
import email
import smtplib
import imaplib
from dotenv import load_dotenv
import os
import time
import sys
root_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.append(root_path)
from src.ollama_local.main import run,run_sec
import json
import pandas as pd
from openpyxl import load_workbook
import subprocess 
from openpyxl.utils import get_column_letter
import gradio 
from email.header import decode_header
from langchain_ollama import OllamaLLM, ChatOllama
load_dotenv()

# Gmail credentials
email_address = os.getenv('EMAIL_ADDRESS')
email_password = os.getenv('EMAIL_PASSWORD')

file_to_extract = "C:/Users/dohuu/Desktop/Ollama_Host/ollama_local/src/ollama_local/tools/text_temp/extracted_images_to_text.txt"





class email_detect:
    def __init__(self):
        self.mail = imaplib.IMAP4_SSL("imap.gmail.com")
    def login_to_email(self):
        print("ƒêang ƒëƒÉng nh·∫≠p ...")
        self.mail = imaplib.IMAP4_SSL("imap.gmail.com")  # Reinitialize
        status, _ = self.mail.login(email_address, email_password)
        print(f"Tr·∫°ng th√°i ƒëƒÉng nh·∫≠p: {status}")
        status, _ = self.mail.select('inbox')
        print(f"Tr·∫°ng th√°i ch·ªçn inbox: {status}")
        return status


    def download_pdf_from_email(self, subject_keyword="PROCESS DOCUMENT"):
        # Search for unread emails with specified subject
        search_query = f'(UNSEEN SUBJECT "{subject_keyword}")'
        status, data = self.mail.search(None, search_query)

        if status != "OK":
            return None

        email_ids = data[0].split()
        if not email_ids:
            return None

        for num in email_ids:
            result, data = self.mail.fetch(num, "(RFC822)")
            if result != "OK":
                continue

            raw_email = data[0][1]
            msg = email.message_from_bytes(raw_email)

            subject = msg["Subject"] or ""
            print(f"üì¨ ƒêang ki·ªÉm tra email v·ªõi ti√™u ƒë·ªÅ: {subject}")

            for part in msg.walk():
                filename = part.get_filename()

                if filename:
                    # Decode filename if needed
                    decoded_parts = decode_header(filename)
                    filename = ''.join([
                        (text.decode(enc) if isinstance(text, bytes) else text)
                        for text, enc in decoded_parts
                    ])

                    if filename.lower().endswith(".pdf"):
                        safe_filename = filename.replace(" ", "_").replace("/", "_")
                        filepath = os.path.join("C:/Users/dohuu/Desktop/TestPDF", safe_filename)
                        with open(filepath, "wb") as f:
                            f.write(part.get_payload(decode=True))
                        print(f"‚úÖ ƒê√£ t·∫£i xu·ªëng: {filepath}")
                        return filepath

        return None

   

    def extracted_to_json(self,file_to_extract,json_path):
        
        with open(file_to_extract,"r",encoding="utf-8") as f:
            raw_text = f.read()
        prompt = f"""
                You are an AI assistant that reads raw text extracted from a PDF invoice.

                Your job is to extract the raw txt I provided in JSON format.
                Always include the following keys (even if null) report it as like this format:

                - invoice_number
                - B√°o_gi√°_ng√†y_th√°ng_nƒÉm 
                - STT (ch·ªâ ghi s·ªë)
                - M√¥_t·∫£_s·∫£n_ph·∫©m (li·ªát k√™: t·∫•t_c·∫£_t√™n_s·∫£n_ph·∫©m, s·ªë_l∆∞·ª£ng, ƒë∆°n_gi√°, th√†nh_ti·ªÅn,b·∫£o_h√†nh,ƒêVT(c√°i,...))
                - Ghi ch√∫
                - fee (t√¨m t·ª´ kh√≥a nh∆∞ VAT ho·∫∑c thu·∫ø ƒë·ªÉ l·∫•y s·ªë ti·ªÅn thu·∫ø, ho·∫∑c l√†m ph√©p t√≠nh v·ªõi c·ªông thanh to√°n v√† c·ªông th√†nh ti·ªÅn ƒë·ªÉ t√¨m s·ªë thu·∫ø)
                - fee_percentage (t√¨m t·ª´ kh√≥a nh∆∞ VAT ? %, ho·∫∑c ph·∫ßn trƒÉm thu·∫ø ho·∫∑c l√†m ph√©p t√≠nh fee ho·∫∑c thu·∫ø ƒë√£ ƒë∆∞·ª£c t√¨m th·∫•y v·ªõi c·ªông th√†nh ti·ªÅn ƒë·ªÉ t√¨m ph·∫ßn trƒÉm)
                - C·ªông_th√†nh_ti·ªÅn
                - C·ªông_thanh_to√°n
                


                D√πng nh·ªØng key ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh b√™n tr√™n. ƒê·ª´ng t·∫°o m·ªõi c√°c t·ª´ kh√°c v√† ƒë·ª´ng l√†m gi·∫£ s·ªë li·ªáu. N·∫øu 
                kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu h√£y ƒë·ªÉ null.

                Raw text:
                {raw_text}
                                                        
                Return only JSON. No explanations.
                Do not return unrelated schemas such as purchase requests or contracts. 
                If the document doesn't match the schema, return null values for all keys instead of creating your own fields.
                Output only JSON.
                """
        llm = ChatOllama(
                model = "qwen2.5:7b",
                #api_key = os.getenv("API_BASE"),
                base_url = os.getenv("API_BASE")
            )



        response = llm.invoke(prompt)
        content = response.content if hasattr(response, "content") else str(response)

        
        try:
            parsed = json.loads(content)
            with open(json_path, "w", encoding="utf-8") as jf:
                json.dump(parsed, jf, indent=2, ensure_ascii=False)
            print(f"Structured JSON saved to {json_path}")
            return parsed
        except Exception as e:
            print("Failed to parse or save JSON from Ollama response.")
            print("Raw response:\n", content)
            return None
    
    


    def ask_questions_loop(self, filepath):
        run(filepath)
        while True:
            question = input("Nh·∫≠p c√¢u h·ªèi v·ªÅ file PDF (ho·∫∑c nh·∫≠p /bye ƒë·ªÉ tho√°t): ").strip()
            if question.lower() == "/bye":
                break
            run_sec(filepath, question)

        
        #json_path = file_to_extract.replace(".txt", ".json")
        #if os.path.exists(json_path):
        #    os.remove(json_path)
        #self.extracted_to_json(file_to_extract, json_path)
        #excel_path = "C:/Users/dohuu/Desktop/TestPDF/Book1.xlsx"
        #self.json_to_excel(json_path, excel_path)
        json_path = "C:/Users/dohuu/Desktop/Ollama_Host/ollama_local/src/ollama_local/tools/text_temp/extracted_images_to_text.json"

        
        if os.path.exists(json_path):
            os.remove(json_path)

       
        self.extracted_to_json(file_to_extract, json_path)

        
        excel_path = "C:/Users/dohuu/Desktop/TestPDF/Book1.xlsx"
        self.json_to_excel(json_path, excel_path)


    def json_to_excel(self, json_path, excel_path):
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        
        date = data.get("B√°o_gi√°_ng√†y_th√°ng_nƒÉm", "")
        items = data.get("M√¥_t·∫£_s·∫£n_ph·∫©m", [])
        total_amount = data.get("C·ªông_th√†nh_ti·ªÅn", "")
        final_amount = data.get("C·ªông_thanh_to√°n", "")
        fee = data.get("fee")
        fee_percentage = data.get("fee_percentage")
        num = data.get("STT")
        note = data.get("Ghi_ch√∫")
        dvt = data.get("ƒêVT")
        stt = data.get("STT")
        
        


        rows = []
        for item in items:
            rows.append({
                "Ng√†y": date,
                "STT": stt,
                "M√¥ t·∫£ s·∫£n ph·∫©m" : item.get("t·∫•t_c·∫£_t√™n_s·∫£n_ph·∫©m",""),
                "ƒêVT" : item.get("ƒêVT"),
                "S·ªë l∆∞·ª£ng" : item.get("s·ªë_l∆∞·ª£ng"),
                "ƒê∆°n gi√°": item.get("ƒë∆°n_gi√°"),
                "Th√†nh ti·ªÅn" : item.get("th√†nh_ti·ªÅn"),
                "Ghi ch√∫" : item.get("b·∫£o_h√†nh"),
                "Ghi ch√∫ th√™m" : note
                
            })
        rows.append({"C·ªông th√†nh ti·ªÅn" : total_amount,
                    "VAT %" : fee_percentage,
                    "VAT" : fee,
                    "C·ªông thanh to√°n" : final_amount,})



        df = pd.DataFrame(rows, columns=["Ng√†y","STT","M√¥ t·∫£ s·∫£n ph·∫©m","ƒêVT","S·ªë l∆∞·ª£ng","ƒê∆°n gi√°","Th√†nh ti·ªÅn","Ghi ch√∫","C·ªông th√†nh ti·ªÅn","VAT %","VAT","C·ªông thanh to√°n","Ghi ch√∫ th√™m"])
        df["ƒê∆°n gi√°"] = pd.to_numeric(df["ƒê∆°n gi√°"], errors="coerce").fillna(0).astype(int)
        
        if os.path.exists(excel_path):
            book = load_workbook(excel_path)
            sheet = book["Sheet1"]
            startrow = sheet.max_row
            book.close()
            mode = 'a'
            header = False  
        else:
            startrow = 0
            mode = 'w'
            header = True  

        with pd.ExcelWriter(excel_path, engine='openpyxl', mode=mode, if_sheet_exists='overlay') as writer:
            df.to_excel(writer, sheet_name="Sheet1", index=False, header=header, startrow=startrow)

        try:
            subprocess.run(["start", excel_path], check=False, shell=True)
        except Exception as e:
            print("Kh√¥ng th·ªÉ m·ªü Excel t·ª± ƒë·ªông:", e)



    #test section

    # Run initial processing once
    def process_pdf(self, filepath):
        run(filepath)  # This is your main analysis function
        return f"PDF processed: {os.path.basename(filepath)}"

    # Answer one question at a time (used in chat)
    def answer_question(self, filepath, question):
        return run_sec(filepath, question)

    # After Q&A, export to Excel
    def finalize_to_excel(self):
        json_path = "C:/Users/dohuu/Desktop/Ollama_Host/ollama_local/src/ollama_local/tools/text_temp/extracted_images_to_text.json"
    
        # Remove existing JSON file if it exists
        if os.path.exists(json_path):
            os.remove(json_path)
        
        # Check if the text file exists before processing
        if not os.path.exists(file_to_extract):
            return f"Error: Text file not found at {file_to_extract}"
        
        # Try to extract and create JSON
        try:
            parsed_data = self.extracted_to_json(file_to_extract, json_path)
            if parsed_data is None:
                return "Error: Failed to extract data to JSON"
            
            # Check if JSON file was actually created
            if not os.path.exists(json_path):
                return f"Error: JSON file was not created at {json_path}"
            
            # Proceed with Excel export
            excel_path = "C:/Users/dohuu/Desktop/TestPDF/Book1.xlsx"
            self.json_to_excel(json_path, excel_path)
            return f"Data exported to Excel: {excel_path}"
            
        except Exception as e:
            return f"Error during processing: {str(e)}"













    #simple web test
def process_email_pipeline():
    email_detection = email_detect()
    if email_detection.login_to_email() == "OK":
        
        
        filepath = email_detection.download_pdf_from_email()
        if filepath:
            email_detection.ask_questions_loop(filepath)
            return "PDF found, processed, questions answered, and Excel updated."
        else:
            return "No matching PDF email found."
    else:
        return "Failed to login to email."
email_detection = email_detect()
global_pdf_filepath = None  # For sharing PDF across interface

def fetch_and_process_pdf():
    global global_pdf_filepath
    if email_detection.login_to_email() == "OK":
        filepath = email_detection.download_pdf_from_email()
        if filepath:
            global_pdf_filepath = filepath
            process_msg = email_detection.process_pdf(filepath)
            return f"PDF downloaded and processed: {os.path.basename(filepath)}.\n{process_msg}"
        else:
            return "No matching PDF email found."
    else:
        return "Failed to login to email."

def chat_with_pdf(question, chat_history):
    if not global_pdf_filepath:
        return "Please fetch and process a PDF first.", chat_history

    answer = email_detection.answer_question(global_pdf_filepath, question)
    chat_history.append((question, answer))
    return "", chat_history

def export_excel():
    msg = email_detection.finalize_to_excel()
    return msg

with gradio.Blocks() as demo:
    gradio.Markdown("## üìß PDF Invoice Processor + AI Q&A + Excel Export")

    fetch_button = gradio.Button("üì• Fetch and Process PDF")
    status_box = gradio.Textbox(label="System Status")

    fetch_button.click(fetch_and_process_pdf, outputs=status_box)

    chatbot = gradio.Chatbot(label="AI Q&A about PDF")
    question_input = gradio.Textbox(label="Ask a Question about the PDF")

    question_input.submit(chat_with_pdf, inputs=[question_input, chatbot], outputs=[question_input, chatbot])

    export_button = gradio.Button("üìä Export Data to Excel")
    export_result = gradio.Textbox(label="Export Status")

    export_button.click(export_excel, outputs=export_result)

demo.launch()



#if __name__ == "__main__":
    # email_detection = email_detect()
    # if email_detection.login_to_email() == "OK":
    #     print("ƒêƒÉng nh·∫≠p th√†nh c√¥ng! B·∫Øt ƒë·∫ßu qu√©t email...\n")

    #     try:
    #         while True:
    #             print("ƒêang ki·ªÉm tra email m·ªõi...")
    #             status, _ = self.mail.select('inbox')
    #             filepath = email_detection.download_pdf_from_email()

    #             if filepath:
    #                 print("File PDF m·ªõi ƒë√£ ƒë∆∞·ª£c t·∫£i v·ªÅ.")
    #                 email_detection.ask_questions_loop(filepath)
    #             else:
    #                 print("Kh√¥ng c√≥ email ph√π h·ª£p. S·∫Ω ki·ªÉm tra l·∫°i sau 5 gi√¢y...\n")

    #             time.sleep(5)

    #     except KeyboardInterrupt:
    #         print("\nCh∆∞∆°ng tr√¨nh ƒë√£ ƒë∆∞·ª£c d·ª´ng th·ªß c√¥ng.")
    
